{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/taker/src')\n",
    "\n",
    "from taker import Model\n",
    "from taker.activations import get_midlayer_data\n",
    "from taker.data_classes import PruningConfig, RunDataHistory, RunDataItem\n",
    "from taker.model_repos import test_model_repos\n",
    "from taker.prune import prune_and_evaluate, run_pruning\n",
    "from taker.eval import evaluate_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_peaks(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for histogram calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Prepare for histogram computation\n",
    "    min_val = activations_float32.min()\n",
    "    max_val = activations_float32.max()\n",
    "    bins = 100\n",
    "\n",
    "    # Initialize an empty tensor to hold the peak values\n",
    "    peak_values_float32 = torch.empty(activations_float32.size()[:-1], device=activations_float32.device, dtype=torch.float32)\n",
    "\n",
    "    # Compute the histogram and find the peak for each neuron in every layer\n",
    "    for i in range(activations_float32.size()[0]):  # Assuming the first dimension is layers\n",
    "        print(f\"getting buckets for layer {i}\")\n",
    "        for j in range(activations_float32.size()[1]):  # Assuming the second dimension is neurons\n",
    "            hist = torch.histc(activations_float32[i, j], bins=bins, min=min_val, max=max_val)\n",
    "            peak_bin = hist.argmax()\n",
    "            # Compute the center value of the peak bin\n",
    "            bin_width = (max_val - min_val) / bins\n",
    "            peak_value = min_val + bin_width * (peak_bin.float() + 0.5)\n",
    "            peak_values_float32[i, j] = peak_value\n",
    "\n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        peak_values = peak_values_float32.half()\n",
    "    else:\n",
    "        peak_values = peak_values_float32\n",
    "\n",
    "    return peak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44eddb0a1cfd49b99f98259695a08892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'google/gemma-2b' with bfp16:\n",
      "- Added 288 hooks across 18 layers\n",
      "1\n",
      "hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pile: 10199it [00:17, 581.17it/s]                            \n",
      "code: 10742it [00:15, 698.71it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "hi!\n",
      "Number of steps: 10\n",
      "3\n",
      "hi!\n",
      "getting ff peaks\n",
      "getting buckets for layer 0\n",
      "getting buckets for layer 1\n",
      "getting buckets for layer 2\n",
      "getting buckets for layer 3\n",
      "getting buckets for layer 4\n",
      "getting buckets for layer 5\n",
      "getting buckets for layer 6\n",
      "getting buckets for layer 7\n",
      "getting buckets for layer 8\n",
      "getting buckets for layer 9\n",
      "getting buckets for layer 10\n",
      "getting buckets for layer 11\n",
      "getting buckets for layer 12\n",
      "getting buckets for layer 13\n",
      "getting buckets for layer 14\n",
      "getting buckets for layer 15\n",
      "getting buckets for layer 16\n",
      "getting buckets for layer 17\n",
      "getting buckets for layer 0\n",
      "getting buckets for layer 1\n",
      "getting buckets for layer 2\n",
      "getting buckets for layer 3\n",
      "getting buckets for layer 4\n",
      "getting buckets for layer 5\n",
      "getting buckets for layer 6\n",
      "getting buckets for layer 7\n",
      "getting buckets for layer 8\n",
      "getting buckets for layer 9\n",
      "getting buckets for layer 10\n",
      "getting buckets for layer 11\n",
      "getting buckets for layer 12\n",
      "getting buckets for layer 13\n",
      "getting buckets for layer 14\n",
      "getting buckets for layer 15\n",
      "getting buckets for layer 16\n",
      "getting buckets for layer 17\n",
      "peak shapes: \n",
      "ff:  + torch.Size([18, 16384])\n",
      "4\n",
      "hi!\n",
      "getting attn peaks\n",
      "getting buckets for layer 0\n",
      "getting buckets for layer 1\n",
      "getting buckets for layer 2\n",
      "getting buckets for layer 3\n",
      "getting buckets for layer 4\n",
      "getting buckets for layer 5\n",
      "getting buckets for layer 6\n",
      "getting buckets for layer 7\n",
      "getting buckets for layer 8\n",
      "getting buckets for layer 9\n",
      "getting buckets for layer 10\n",
      "getting buckets for layer 11\n",
      "getting buckets for layer 12\n",
      "getting buckets for layer 13\n",
      "getting buckets for layer 14\n",
      "getting buckets for layer 15\n",
      "getting buckets for layer 16\n",
      "getting buckets for layer 17\n",
      "getting buckets for layer 0\n",
      "getting buckets for layer 1\n",
      "getting buckets for layer 2\n",
      "getting buckets for layer 3\n",
      "getting buckets for layer 4\n",
      "getting buckets for layer 5\n",
      "getting buckets for layer 6\n",
      "getting buckets for layer 7\n",
      "getting buckets for layer 8\n",
      "getting buckets for layer 9\n",
      "getting buckets for layer 10\n",
      "getting buckets for layer 11\n",
      "getting buckets for layer 12\n",
      "getting buckets for layer 13\n",
      "getting buckets for layer 14\n",
      "getting buckets for layer 15\n",
      "getting buckets for layer 16\n",
      "getting buckets for layer 17\n",
      "-----------------\n",
      "ff reshaped:  + torch.Size([18, 16384, 10199])\n",
      "ff original:  + torch.Size([10199, 18, 16384])\n",
      "ff peaks:  + torch.Size([18, 16384])\n",
      "attn reshaped:  + torch.Size([18, 2048, 10199])\n",
      "attn original:  + torch.Size([10199, 18, 8, 256])\n",
      "attn peaks:  + torch.Size([18, 8, 256])\n",
      "5\n",
      "hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pile: 10199it [00:22, 457.15it/s]                            \n",
      "code: 10742it [00:25, 424.00it/s]                            \n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbpas992\u001b[0m (\u001b[33mseperability\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/taker/examples/investigating-ablation/wandb/run-20241014_000721-z79q9xtz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seperability/bens-tests/runs/z79q9xtz' target=\"_blank\">gemma-2b peak scoring. ff=0.1 attn=0.1</a></strong> to <a href='https://wandb.ai/seperability/bens-tests' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seperability/bens-tests' target=\"_blank\">https://wandb.ai/seperability/bens-tests</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seperability/bens-tests/runs/z79q9xtz' target=\"_blank\">https://wandb.ai/seperability/bens-tests/runs/z79q9xtz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 93.36|77.83 (Skip: 90.40|72.59): : 100033it [00:43, 2304.44it/s]                           \n",
      "pile     Acc: 85.16|57.19 (Skip: 81.72|52.72): : 100116it [00:38, 2599.02it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 90.51|66.09 (Skip: 86.35|58.88): : 100033it [00:44, 2264.37it/s]                           \n",
      "pile     Acc: 81.47|49.04 (Skip: 77.24|44.24): : 100116it [00:37, 2702.26it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 75.37|39.34 (Skip: 66.68|30.08): : 100033it [00:43, 2281.74it/s]                           \n",
      "pile     Acc: 68.19|32.17 (Skip: 62.52|28.17): : 100116it [00:36, 2729.82it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 40.06|15.39 (Skip: 27.63|8.57): : 100033it [00:43, 2299.77it/s]                           \n",
      "pile     Acc: 46.57|18.08 (Skip: 39.13|15.35): : 100116it [00:36, 2744.59it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 17.57|5.48 (Skip: 9.04|2.40): : 100033it [00:43, 2277.54it/s]                           \n",
      "pile     Acc: 23.34|6.83 (Skip: 16.28|5.27): : 100116it [00:36, 2713.14it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 7.86|2.04 (Skip: 3.05|0.66): : 100033it [00:43, 2303.78it/s]                           \n",
      "pile     Acc: 10.61|2.63 (Skip: 5.91|1.64): : 100116it [00:36, 2739.89it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 2048112 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'code' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 5.13|1.20 (Skip: 1.30|0.22):  86%|████████▌ | 85736/100000.0 [00:37<00:05, 2720.20it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 108\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(c\u001b[38;5;241m.\u001b[39mn_steps):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mprune_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocus_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcripple_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     history\u001b[38;5;241m.\u001b[39madd(data)\n",
      "File \u001b[0;32m~/taker/src/taker/prune.py:65\u001b[0m, in \u001b[0;36mprune_and_evaluate\u001b[0;34m(opt, pruning_config, focus_out, cripple_out, iteration)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 65\u001b[0m     eval_out \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_sample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset_tokens_to_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection_sample_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     data\u001b[38;5;241m.\u001b[39mupdate(eval_out)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/taker/src/taker/eval.py:1248\u001b[0m, in \u001b[0;36mevaluate_all\u001b[0;34m(opt, sample_size, datasets, dataset_tokens_to_skip, topk, verbose)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     eval_config\u001b[38;5;241m.\u001b[39mtopk         \u001b[38;5;241m=\u001b[39m topk\n\u001b[1;32m   1246\u001b[0m     eval_config\u001b[38;5;241m.\u001b[39mverbose      \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m-> 1248\u001b[0m     dataset_out \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m     out\u001b[38;5;241m.\u001b[39madd(dataset, dataset_out)\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/taker/src/taker/eval.py:685\u001b[0m, in \u001b[0;36mrun_evaluation\u001b[0;34m(model, eval_config, get_generator, dataset_evaluator)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# Run Evaluation\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 685\u001b[0m     out: EvalOutput \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m out\u001b[38;5;241m.\u001b[39mmisc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_config\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/taker/src/taker/eval.py:545\u001b[0m, in \u001b[0;36mEvaluator.evaluate_dataset\u001b[0;34m(self, generator, eval_config)\u001b[0m\n\u001b[1;32m    542\u001b[0m     expected_ids \u001b[38;5;241m=\u001b[39m expected_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, c\u001b[38;5;241m.\u001b[39mstart_index:]\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Assess performance on a sample\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m sample_acc_data, _sample_misc_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_topk_performance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_token_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m sample_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_ce_losses(\n\u001b[1;32m    550\u001b[0m     expected_ids\u001b[38;5;241m=\u001b[39mexpected_ids, logits\u001b[38;5;241m=\u001b[39mlogits,\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# Record performance\u001b[39;00m\n",
      "File \u001b[0;32m~/taker/src/taker/eval.py:478\u001b[0m, in \u001b[0;36mEvaluator.evaluate_topk_performance\u001b[0;34m(self, expected_ids, logits, k, skip_ids)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, expected_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text_expected_ids):\n\u001b[1;32m    477\u001b[0m     expected_id \u001b[38;5;241m=\u001b[39m expected_id\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 478\u001b[0m     is_accurate      \u001b[38;5;241m=\u001b[39m (\u001b[43mexpected_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtop_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    479\u001b[0m     is_topk_accurate \u001b[38;5;241m=\u001b[39m (expected_id \u001b[38;5;129;01min\u001b[39;00m topk_tokens[j][i])\n\u001b[1;32m    481\u001b[0m     acc\u001b[38;5;241m.\u001b[39mnum_predictions   \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/taker-807OG091-py3.10/lib/python3.10/site-packages/torch/_tensor.py:1112\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__contains__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, element)\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1109\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[1;32m   1110\u001b[0m ):\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1116\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code     Acc: 5.13|1.20 (Skip: 1.30|0.22):  86%|████████▌ | 85736/100000.0 [00:50<00:05, 2720.20it/s]"
     ]
    }
   ],
   "source": [
    "c = PruningConfig(\"google/gemma-2b\",\n",
    "#c = PruningConfig(\"facebook/galactica-1.3b\",\n",
    "#c = PruningConfig(\"facebook/opt-1.3b\",\n",
    "#c = PruningConfig(\"nickypro/tinyllama-15m\",\n",
    "    attn_mode=\"pre-out\", do_attn_mean_offset=False, use_accelerator=False,\n",
    "    ff_frac=0.1, attn_frac=0.1,\n",
    "    token_limit=1000, focus=\"pile\", cripple=\"code\", wandb_entity=\"seperability\", recalculate_activations=False, dtype=\"fp32\",\n",
    "    #wandb_project=\"bens-tests\", wandb_run_name=\"OPT-1.3b orig scoring. ff=0.1 attn=0.1\", n_steps=10)\n",
    "    wandb_project=\"bens-tests\", wandb_run_name=\"gemma-2b peak scoring. ff=0.1 attn=0.1\", n_steps=10, scoring_normalization=\"peak_centered\")\n",
    "    #wandb_project=\"bens-tests\", wandb_run_name=\"gemma-2b orig scoring. ff=0.1 attn=0.1\", n_steps=10)\n",
    "    #wandb_project=\"bens-tests\", wandb_run_name=\"test notebook2\", n_steps=10)\n",
    "\n",
    "opt: Model = Model(c.model_repo, limit=c.token_limit, #dtype=\"nf4\",\n",
    "            use_accelerator=c.use_accelerator)\n",
    "#focus_data = get_midlayer_activations( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True )\n",
    "#cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True )\n",
    "\n",
    "print_gpu_memory_usage()\n",
    "focus_data = get_midlayer_data( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True )\n",
    "cripple_data = get_midlayer_data( opt, \"code\", 1e4, collect_ff=True, collect_attn=True )\n",
    "print_gpu_memory_usage()\n",
    "\n",
    "#FIXME: delete\n",
    "#print the shapes of the activations\n",
    "#print(\"focus shapes: \")\n",
    "#print(f\"ff:  + {focus_data.raw['ff'].shape}\")\n",
    "#print(f\"attn:  + {focus_data.raw['attn'].shape}\")\n",
    "\n",
    "# [token, layer, neuron] -> [layer, neuron, token]\n",
    "#focus_ff_activations   = focus_data[\"raw\"][\"mlp\"].permute( (1,2,0) )\n",
    "focus_ff_activations   = focus_data.raw[\"mlp\"].permute( (1,2,0) )\n",
    "cripple_ff_activations = cripple_data.raw[\"mlp\"].permute( (1,2,0) )\n",
    "# [token, layer, attention head, attention neuron] -> [layer, attention head, attention neuron, token]\n",
    "focus_attn_activations   = focus_data.raw[\"attn\"].permute( (1,2,3,0) ).reshape( (opt.cfg.n_layers, opt.cfg.d_model, -1) )\n",
    "cripple_attn_activations = cripple_data.raw[\"attn\"].permute( (1,2,3,0) ).reshape( (opt.cfg.n_layers, opt.cfg.d_model, -1) )\n",
    "\n",
    "print(\"3\")\n",
    "print_gpu_memory_usage()\n",
    "print(\"getting ff peaks\")\n",
    "focus_ff_peaks = get_bucket_peaks(focus_ff_activations).cuda()\n",
    "cripple_ff_peaks = get_bucket_peaks(cripple_ff_activations).cuda()\n",
    "\n",
    "#print peak shapes\n",
    "print(\"peak shapes: \")\n",
    "print(f\"ff:  + {focus_ff_peaks.shape}\")\n",
    "\n",
    "#tinyllama-15m\n",
    "#focus_attn_peaks = get_bucket_peaks(focus_attn_activations).reshape(6, 6, 48).cuda()\n",
    "#cripple_attn_peaks = get_bucket_peaks(cripple_attn_activations).reshape(6, 6, 48).cuda()\n",
    "\n",
    "#opt1.3b\n",
    "#focus_attn_peaks = get_bucket_peaks(focus_attn_activations).reshape(24, 32, 64).cuda()\n",
    "#cripple_attn_peaks = get_bucket_peaks(cripple_attn_activations).reshape(24, 32, 64).cuda()\n",
    "\n",
    "print(\"4\")\n",
    "print_gpu_memory_usage()\n",
    "#gemma 2b\n",
    "print(\"getting attn peaks\")\n",
    "focus_attn_peaks = get_bucket_peaks(focus_attn_activations).reshape(18, 8, 256).cuda()\n",
    "cripple_attn_peaks = get_bucket_peaks(cripple_attn_activations).reshape(18, 8, 256).cuda()\n",
    "\n",
    "# test reversing the shapes of the activatons\n",
    "print(\"-----------------\")\n",
    "print(f\"ff reshaped:  + {focus_ff_activations.shape}\")\n",
    "print(f\"ff original:  + {focus_data.raw['mlp'].shape}\")\n",
    "print(f\"ff peaks:  + {focus_ff_peaks.shape}\")\n",
    "\n",
    "#same thing with attn\n",
    "print(f\"attn reshaped:  + {focus_attn_activations.shape}\")\n",
    "print(f\"attn original:  + {focus_data.raw['attn'].shape}\")\n",
    "print(f\"attn peaks:  + {focus_attn_peaks.shape}\")\n",
    "\n",
    "# Now get activation data again with peaks offsets\n",
    "#This was breaking things before (kernel restart)\n",
    "focus_data   = get_midlayer_data( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True, ff_peak=focus_ff_peaks, attn_peak=focus_attn_peaks )\n",
    "cripple_data = get_midlayer_data( opt, \"code\", 1e4, collect_ff=True, collect_attn=True, ff_peak=cripple_ff_peaks,  attn_peak=cripple_attn_peaks )\n",
    "\n",
    "#print(\"focus data: \")\n",
    "#print(focus_data.ff.peak_centered)\n",
    "#only ff peaks\n",
    "#cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True, ff_peak=cripple_ff_peaks)\n",
    "\n",
    "history = RunDataHistory(c.datasets)\n",
    "wandb.init(\n",
    "    project=c.wandb_project,\n",
    "    entity=c.wandb_entity,\n",
    "    name=c.wandb_run_name,\n",
    "    )\n",
    "wandb.config.update(c.to_dict(), allow_val_change=True)\n",
    "\n",
    "\n",
    "print(\"6\")\n",
    "print_gpu_memory_usage()\n",
    "with torch.no_grad(): \n",
    "    #evaluate without pruning first\n",
    "    data = RunDataItem()\n",
    "    eval_out = evaluate_all(opt, c.eval_sample_size, c.datasets,\n",
    "                            dataset_tokens_to_skip=c.collection_sample_size)\n",
    "    data.update(eval_out)\n",
    "    history.add(data)\n",
    "    for i in range(c.n_steps):\n",
    "        print (f\"step {i}\")\n",
    "        data = prune_and_evaluate(opt, c, focus_data, cripple_data, i)\n",
    "        history.add(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taker-807OG091-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
