{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/taker/src')\n",
    "\n",
    "from taker import Model\n",
    "from taker.activations import get_midlayer_activations\n",
    "from taker.data_classes import PruningConfig, RunDataHistory\n",
    "from taker.model_repos import test_model_repos\n",
    "from taker.prune import prune_and_evaluate, run_pruning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_peaks(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for histogram calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Prepare for histogram computation\n",
    "    min_val = activations_float32.min()\n",
    "    max_val = activations_float32.max()\n",
    "    bins = 100\n",
    "\n",
    "    # Initialize an empty tensor to hold the peak values\n",
    "    peak_values_float32 = torch.empty(activations_float32.size()[:-1], device=activations_float32.device, dtype=torch.float32)\n",
    "\n",
    "    # Compute the histogram and find the peak for each neuron in every layer\n",
    "    for i in range(activations_float32.size()[0]):  # Assuming the first dimension is layers\n",
    "        for j in range(activations_float32.size()[1]):  # Assuming the second dimension is neurons\n",
    "            hist = torch.histc(activations_float32[i, j], bins=bins, min=min_val, max=max_val)\n",
    "            peak_bin = hist.argmax()\n",
    "            # Compute the center value of the peak bin\n",
    "            bin_width = (max_val - min_val) / bins\n",
    "            peak_value = min_val + bin_width * (peak_bin.float() + 0.5)\n",
    "            peak_values_float32[i, j] = peak_value\n",
    "\n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        peak_values = peak_values_float32.half()\n",
    "    else:\n",
    "        peak_values = peak_values_float32\n",
    "\n",
    "    return peak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded nickypro/tinyllama-15m\n",
      " - Registered 6 Attention Layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1830d7afce740c69ee10004e5f0aac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000.0 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3324 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 90%|█████████ | 9048/10000.0 [00:16<00:01, 543.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m c \u001b[38;5;241m=\u001b[39m PruningConfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnickypro/tinyllama-15m\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m     attn_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-out\u001b[39m\u001b[38;5;124m\"\u001b[39m, do_attn_mean_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m     ff_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, attn_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      4\u001b[0m     token_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, focus\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpile\u001b[39m\u001b[38;5;124m\"\u001b[39m, cripple\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, wandb_entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseperability\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     wandb_project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbens-tests\u001b[39m\u001b[38;5;124m\"\u001b[39m, wandb_run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,)\n\u001b[1;32m      7\u001b[0m opt: Model \u001b[38;5;241m=\u001b[39m Model(c\u001b[38;5;241m.\u001b[39mmodel_repo, limit\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mtoken_limit, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             use_accelerator\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39muse_accelerator)\n\u001b[0;32m----> 9\u001b[0m focus_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_midlayer_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_ff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m cripple_data \u001b[38;5;241m=\u001b[39m get_midlayer_activations( opt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e4\u001b[39m, collect_ff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collect_attn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[1;32m     12\u001b[0m history \u001b[38;5;241m=\u001b[39m RunDataHistory(c\u001b[38;5;241m.\u001b[39mdatasets)\n",
      "File \u001b[0;32m~/taker/src/taker/activations.py:300\u001b[0m, in \u001b[0;36mget_midlayer_activations\u001b[0;34m(opt, dataset_name, sample_size, attn_mode, check_accuracy, calculate_loss, k, check_skips, skip_ids, skip_type, skip_input_or_output, calculate_ff, calculate_attn, collect_ff, collect_attn, collect_ids, use_ff_activation_function, dataset_texts_to_skip, random_subset_frac, eval_config, masked_mode)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criteria[token_index]:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[43mff_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mff_activation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/taker/src/taker/data_classes.py:488\u001b[0m, in \u001b[0;36mActivationCollector.add\u001b[0;34m(self, data_point)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# Get information about positive and negative activations\u001b[39;00m\n\u001b[1;32m    487\u001b[0m pos_points \u001b[38;5;241m=\u001b[39m (data_point\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_point\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpos_points\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneg\u001b[38;5;241m.\u001b[39madd(data_point \u001b[38;5;241m*\u001b[39m pos_points\u001b[38;5;241m.\u001b[39mlogical_not() )\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Add number of positive activations to pos_counter\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "c = PruningConfig(\"nickypro/tinyllama-15m\",\n",
    "    attn_mode=\"pre-out\", do_attn_mean_offset=False, use_accelerator=False,\n",
    "    ff_frac=0.5, attn_frac=0.5,\n",
    "    token_limit=1000, focus=\"pile\", cripple=\"code\", wandb_entity=\"seperability\",\n",
    "    wandb_project=\"bens-tests\", wandb_run_name=\"test notebook2\", n_steps=10,)\n",
    "\n",
    "opt: Model = Model(c.model_repo, limit=c.token_limit, dtype=\"fp32\",\n",
    "            use_accelerator=c.use_accelerator)\n",
    "focus_data = get_midlayer_activations( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True )\n",
    "cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True )\n",
    "\n",
    "history = RunDataHistory(c.datasets)\n",
    "wandb.init(\n",
    "    project=c.wandb_project,\n",
    "    entity=c.wandb_entity,\n",
    "    name=c.wandb_run_name,\n",
    "    )\n",
    "wandb.config.update(c.to_dict(), allow_val_change=True)\n",
    "with torch.no_grad():\n",
    "    for i in range(c.n_steps):\n",
    "        data = prune_and_evaluate(opt, c, focus_data, cripple_data, i)\n",
    "        history.add(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
