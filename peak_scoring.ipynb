{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6f2eea81f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f6f2e952fe0, raw_cell=\"import torch\n",
      "import wandb\n",
      "\n",
      "import sys\n",
      "sys.path.app..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B147.189.194.88/home/ubuntu/taker/examples/aisc-peak-activations/peak_scoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6f2eea81f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f6f2e9521a0, execution_count=4 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f6f2e952fe0, raw_cell=\"import torch\n",
      "import wandb\n",
      "\n",
      "import sys\n",
      "sys.path.app..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B147.189.194.88/home/ubuntu/taker/examples/aisc-peak-activations/peak_scoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/taker/src')\n",
    "\n",
    "from taker import Model\n",
    "from taker.activations import get_midlayer_activations\n",
    "from taker.data_classes import PruningConfig, RunDataHistory\n",
    "from taker.model_repos import test_model_repos\n",
    "from taker.prune import prune_and_evaluate, run_pruning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6f2eea81f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f704c59fb50, raw_cell=\"def get_bucket_peaks(activations):\n",
      "    # Check if ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B147.189.194.88/home/ubuntu/taker/examples/aisc-peak-activations/peak_scoring.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6f2eea81f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f704c3e7370, execution_count=5 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f704c59fb50, raw_cell=\"def get_bucket_peaks(activations):\n",
      "    # Check if ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B147.189.194.88/home/ubuntu/taker/examples/aisc-peak-activations/peak_scoring.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def get_bucket_peaks(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for histogram calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Prepare for histogram computation\n",
    "    min_val = activations_float32.min()\n",
    "    max_val = activations_float32.max()\n",
    "    bins = 100\n",
    "\n",
    "    # Initialize an empty tensor to hold the peak values\n",
    "    peak_values_float32 = torch.empty(activations_float32.size()[:-1], device=activations_float32.device, dtype=torch.float32)\n",
    "\n",
    "    # Compute the histogram and find the peak for each neuron in every layer\n",
    "    for i in range(activations_float32.size()[0]):  # Assuming the first dimension is layers\n",
    "        for j in range(activations_float32.size()[1]):  # Assuming the second dimension is neurons\n",
    "            hist = torch.histc(activations_float32[i, j], bins=bins, min=min_val, max=max_val)\n",
    "            peak_bin = hist.argmax()\n",
    "            # Compute the center value of the peak bin\n",
    "            bin_width = (max_val - min_val) / bins\n",
    "            peak_value = min_val + bin_width * (peak_bin.float() + 0.5)\n",
    "            peak_values_float32[i, j] = peak_value\n",
    "\n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        peak_values = peak_values_float32.half()\n",
    "    else:\n",
    "        peak_values = peak_values_float32\n",
    "\n",
    "    return peak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6f2eea81f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f6f241839a0, raw_cell=\"c = PruningConfig(\"nickypro/tinyllama-15m\",\n",
      "    at..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B147.189.194.88/home/ubuntu/taker/examples/aisc-peak-activations/peak_scoring.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded nickypro/tinyllama-15m\n",
      " - Registered 6 Attention Layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a9aaa3084942f3995173cdf67f6805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000.0 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3324 > 2048). Running this sequence through the model will result in indexing errors\n",
      "10048it [00:16, 612.14it/s]                            \n",
      "/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "10104it [00:17, 590.37it/s]                            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c6282388b74c81b5a5d06409006f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10048it [00:29, 336.44it/s]                            \n",
      "10104it [00:29, 339.71it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focus data: \n",
      "ActivationSummary(sqrt=tensor([[0.2914, 0.2977, 0.3019,  ..., 0.3287, 0.3192, 0.3376],\n",
      "        [0.3835, 0.3039, 0.2824,  ..., 0.3137, 0.2991, 0.3340],\n",
      "        [0.3224, 0.3057, 0.3186,  ..., 0.3260, 0.3268, 0.4004],\n",
      "        [0.3585, 0.2620, 0.2962,  ..., 0.2966, 0.3816, 0.4146],\n",
      "        [0.3393, 0.5222, 0.2813,  ..., 0.4272, 0.3173, 0.4245],\n",
      "        [0.6673, 0.4202, 0.3683,  ..., 0.4420, 0.4865, 0.5135]],\n",
      "       device='cuda:0'), mean=tensor([[-0.0816, -0.0898, -0.0937,  ..., -0.0209, -0.0899, -0.1144],\n",
      "        [-0.1598, -0.0848, -0.0636,  ..., -0.0918, -0.0821, -0.0976],\n",
      "        [-0.0927, -0.0916, -0.1046,  ..., -0.1022, -0.0477, -0.1901],\n",
      "        [ 0.0107, -0.0389, -0.0625,  ..., -0.0673, -0.0659, -0.1839],\n",
      "        [ 0.0364, -0.2870, -0.0411,  ..., -0.1073, -0.0829,  0.0240],\n",
      "        [-0.3526, -0.1611, -0.1262,  ...,  0.0862,  0.1690, -0.3045]],\n",
      "       device='cuda:0'), std=tensor([[0.0045, 0.0036, 0.0029,  ..., 0.0271, 0.0118, 0.0084],\n",
      "        [0.0242, 0.0108, 0.0079,  ..., 0.0127, 0.0074, 0.0305],\n",
      "        [0.0124, 0.0057, 0.0057,  ..., 0.0079, 0.0263, 0.0530],\n",
      "        [0.0547, 0.0101, 0.0164,  ..., 0.0140, 0.0559, 0.0580],\n",
      "        [0.0323, 0.1554, 0.0123,  ..., 0.0966, 0.0147, 0.1114],\n",
      "        [0.4931, 0.0653, 0.0403,  ..., 0.2461, 0.2474, 0.1107]],\n",
      "       device='cuda:0'), pos_mass=tensor([[0.0050, 0.0025, 0.0011,  ..., 0.0524, 0.0119, 0.0052],\n",
      "        [0.0058, 0.0096, 0.0128,  ..., 0.0105, 0.0086, 0.0190],\n",
      "        [0.0119, 0.0051, 0.0031,  ..., 0.0073, 0.0389, 0.0053],\n",
      "        [0.0861, 0.0211, 0.0205,  ..., 0.0175, 0.0564, 0.0140],\n",
      "        [0.0874, 0.0295, 0.0258,  ..., 0.0610, 0.0155, 0.1277],\n",
      "        [0.1050, 0.0273, 0.0184,  ..., 0.1803, 0.2459, 0.0089]],\n",
      "       device='cuda:0'), pos_var=tensor([[9.1752e-04, 2.5688e-04, 1.1454e-04,  ..., 1.5354e-02, 2.6431e-03,\n",
      "         1.2077e-03],\n",
      "        [8.8659e-04, 2.1487e-03, 2.8851e-03,  ..., 2.1587e-03, 2.2165e-03,\n",
      "         4.5754e-03],\n",
      "        [3.8662e-03, 8.4490e-04, 5.5623e-04,  ..., 1.3653e-03, 9.3418e-03,\n",
      "         1.2250e-03],\n",
      "        [3.0704e-02, 2.1494e-03, 4.5238e-03,  ..., 4.3381e-03, 1.2380e-02,\n",
      "         5.2098e-03],\n",
      "        [1.4751e-02, 1.7825e-02, 3.2541e-03,  ..., 3.2602e-02, 4.8483e-03,\n",
      "         4.8838e-02],\n",
      "        [5.2892e-02, 1.0332e-02, 6.8873e-03,  ..., 1.8337e-01, 1.8181e-01,\n",
      "         3.8449e-03]], device='cuda:0'), neg_mass=tensor([[-0.0866, -0.0923, -0.0948,  ..., -0.0733, -0.1017, -0.1196],\n",
      "        [-0.1657, -0.0944, -0.0764,  ..., -0.1023, -0.0906, -0.1166],\n",
      "        [-0.1046, -0.0967, -0.1076,  ..., -0.1094, -0.0866, -0.1955],\n",
      "        [-0.0754, -0.0600, -0.0831,  ..., -0.0848, -0.1224, -0.1978],\n",
      "        [-0.0510, -0.3165, -0.0669,  ..., -0.1682, -0.0985, -0.1036],\n",
      "        [-0.4576, -0.1884, -0.1446,  ..., -0.0942, -0.0768, -0.3134]],\n",
      "       device='cuda:0'), neg_var=tensor([[0.0027, 0.0029, 0.0026,  ..., 0.0041, 0.0067, 0.0060],\n",
      "        [0.0214, 0.0069, 0.0031,  ..., 0.0084, 0.0036, 0.0214],\n",
      "        [0.0061, 0.0039, 0.0045,  ..., 0.0049, 0.0102, 0.0496],\n",
      "        [0.0110, 0.0054, 0.0085,  ..., 0.0067, 0.0297, 0.0472],\n",
      "        [0.0086, 0.1189, 0.0055,  ..., 0.0435, 0.0068, 0.0361],\n",
      "        [0.3441, 0.0447, 0.0281,  ..., 0.0288, 0.0278, 0.1013]],\n",
      "       device='cuda:0'), pos_count=tensor([[0.0661, 0.0475, 0.0208,  ..., 0.2850, 0.1138, 0.0532],\n",
      "        [0.0701, 0.1026, 0.1338,  ..., 0.1194, 0.0999, 0.1979],\n",
      "        [0.0938, 0.0703, 0.0448,  ..., 0.0873, 0.2841, 0.0617],\n",
      "        [0.4116, 0.3008, 0.2125,  ..., 0.1668, 0.3393, 0.1068],\n",
      "        [0.5261, 0.1402, 0.2980,  ..., 0.2512, 0.1239, 0.4804],\n",
      "        [0.3044, 0.1621, 0.1237,  ..., 0.4318, 0.5193, 0.0667]],\n",
      "       device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:437b6ii6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/code/base</td><td>▄▃▄▃▄▁▁▁▂█</td></tr><tr><td>accuracy/code/skip</td><td>▆▅▆▄█▁▁▁▂▁</td></tr><tr><td>accuracy/code/topk</td><td>█▆█▇█▁▁▁▂█</td></tr><tr><td>accuracy/code/topk_skip</td><td>▇▅▆▆█▁▁▁▁▂</td></tr><tr><td>accuracy/pile/base</td><td>█▆▆▅▅▁▁▁▁▅</td></tr><tr><td>accuracy/pile/skip</td><td>█▆▅▅▇▁▁▁▁▁</td></tr><tr><td>accuracy/pile/topk</td><td>█▆▆▆▅▂▁▁▁▃</td></tr><tr><td>accuracy/pile/topk_skip</td><td>█▇▆▆▇▂▁▁▁▁</td></tr><tr><td>areas/base</td><td>▁▁▄▂█▇▇▇▇▇</td></tr><tr><td>areas/skip</td><td>▁▁▅▁█▇▇▇▇▇</td></tr><tr><td>areas/topk</td><td>▃▁▆▃█▆▆▆▆▇</td></tr><tr><td>areas/topk_skip</td><td>▃▁▆▃█▆▆▆▆▆</td></tr><tr><td>deletions/attn_del</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>deletions/attn_threshold</td><td>█▇▇▆▆▆▅▅▄▁</td></tr><tr><td>deletions/ff_del</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>deletions/ff_threshold</td><td>██▇▇▆▆▅▅▄▁</td></tr><tr><td>init_accuracy/code/base</td><td>▁</td></tr><tr><td>init_accuracy/code/skip</td><td>▁</td></tr><tr><td>init_accuracy/code/topk</td><td>▁</td></tr><tr><td>init_accuracy/code/topk_skip</td><td>▁</td></tr><tr><td>init_accuracy/pile/base</td><td>▁</td></tr><tr><td>init_accuracy/pile/skip</td><td>▁</td></tr><tr><td>init_accuracy/pile/topk</td><td>▁</td></tr><tr><td>init_accuracy/pile/topk_skip</td><td>▁</td></tr><tr><td>loss_data/code/log_loss</td><td>▁▃▁▄▂▅▇▅█ </td></tr><tr><td>loss_data/code/loss</td><td>▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>loss_data/code/perplexity</td><td>▁▁▁▁▁▁▂▁█ </td></tr><tr><td>loss_data/pile/log_loss</td><td>▁▂▂▃▃▅▆▆█ </td></tr><tr><td>loss_data/pile/loss</td><td>▁▁▁▁▁▁▁▁▂█</td></tr><tr><td>loss_data/pile/perplexity</td><td>▁▁▁▁▁▁▁▁█ </td></tr><tr><td>misc/code/accuracy_data/num_accurate</td><td>▄▃▄▃▄▁▁▁▂█</td></tr><tr><td>misc/code/accuracy_data/num_predictions</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/accuracy_data/num_skip_accurate</td><td>▆▅▆▄█▁▁▁▂▁</td></tr><tr><td>misc/code/accuracy_data/num_skip_predictions</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/accuracy_data/num_topk_accurate</td><td>█▆█▇█▁▁▁▂█</td></tr><tr><td>misc/code/accuracy_data/num_topk_skip_accurate</td><td>▇▅▆▆█▁▁▁▁▂</td></tr><tr><td>misc/code/eval_config/dataset_has_test_split</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/generated_text_include_prompt</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/generated_text_length</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/generated_text_num_samples</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/is_train_mode</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_masked</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_randomized</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_unchanged</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/masked_model</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/n_shot</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/num_texts_to_skip</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/num_tokens_to_skip</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/num_top_tokens</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/sample_size</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/start_index</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/streaming</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/topk</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/code/eval_config/verbose</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/accuracy_data/num_accurate</td><td>█▆▆▅▅▁▁▁▁▅</td></tr><tr><td>misc/pile/accuracy_data/num_predictions</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/accuracy_data/num_skip_accurate</td><td>█▆▅▅▇▁▁▁▁▁</td></tr><tr><td>misc/pile/accuracy_data/num_skip_predictions</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/accuracy_data/num_topk_accurate</td><td>█▆▆▆▅▂▁▁▁▃</td></tr><tr><td>misc/pile/accuracy_data/num_topk_skip_accurate</td><td>█▇▆▆▇▂▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/dataset_has_test_split</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/generated_text_include_prompt</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/generated_text_length</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/generated_text_num_samples</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/is_train_mode</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_masked</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_randomized</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_unchanged</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/masked_model</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/n_shot</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/num_texts_to_skip</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/num_tokens_to_skip</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/num_top_tokens</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/sample_size</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/start_index</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/streaming</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/topk</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>misc/pile/eval_config/verbose</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/code/base</td><td>1.83298</td></tr><tr><td>accuracy/code/skip</td><td>0.01397</td></tr><tr><td>accuracy/code/topk</td><td>3.26063</td></tr><tr><td>accuracy/code/topk_skip</td><td>0.92923</td></tr><tr><td>accuracy/pile/base</td><td>1.64419</td></tr><tr><td>accuracy/pile/skip</td><td>0.01198</td></tr><tr><td>accuracy/pile/topk</td><td>4.0174</td></tr><tr><td>accuracy/pile/topk_skip</td><td>0.46007</td></tr><tr><td>areas/base</td><td>1.3341</td></tr><tr><td>areas/skip</td><td>1.34146</td></tr><tr><td>areas/topk</td><td>1.1777</td></tr><tr><td>areas/topk_skip</td><td>1.15598</td></tr><tr><td>deletions/attn_del</td><td>1728.0</td></tr><tr><td>deletions/attn_threshold</td><td>0.23547</td></tr><tr><td>deletions/ff_del</td><td>4608.0</td></tr><tr><td>deletions/ff_threshold</td><td>0.38588</td></tr><tr><td>init_accuracy/code/base</td><td>0.77146</td></tr><tr><td>init_accuracy/code/skip</td><td>0.77852</td></tr><tr><td>init_accuracy/code/topk</td><td>3.38795</td></tr><tr><td>init_accuracy/code/topk_skip</td><td>3.38657</td></tr><tr><td>init_accuracy/pile/base</td><td>2.93467</td></tr><tr><td>init_accuracy/pile/skip</td><td>1.92811</td></tr><tr><td>init_accuracy/pile/topk</td><td>11.39689</td></tr><tr><td>init_accuracy/pile/topk_skip</td><td>7.39107</td></tr><tr><td>loss_data/code/log_loss</td><td>nan</td></tr><tr><td>loss_data/code/loss</td><td>50.6016</td></tr><tr><td>loss_data/code/perplexity</td><td>nan</td></tr><tr><td>loss_data/pile/log_loss</td><td>nan</td></tr><tr><td>loss_data/pile/loss</td><td>51.9032</td></tr><tr><td>loss_data/pile/perplexity</td><td>nan</td></tr><tr><td>misc/code/accuracy_data/num_accurate</td><td>2433</td></tr><tr><td>misc/code/accuracy_data/num_predictions</td><td>132735</td></tr><tr><td>misc/code/accuracy_data/num_skip_accurate</td><td>14</td></tr><tr><td>misc/code/accuracy_data/num_skip_predictions</td><td>100190</td></tr><tr><td>misc/code/accuracy_data/num_topk_accurate</td><td>4328</td></tr><tr><td>misc/code/accuracy_data/num_topk_skip_accurate</td><td>931</td></tr><tr><td>misc/code/eval_config/dataset_has_test_split</td><td>False</td></tr><tr><td>misc/code/eval_config/dataset_image_key</td><td>image</td></tr><tr><td>misc/code/eval_config/dataset_image_label_key</td><td>label</td></tr><tr><td>misc/code/eval_config/dataset_name</td><td>code</td></tr><tr><td>misc/code/eval_config/dataset_repo</td><td>codeparrot/github-co...</td></tr><tr><td>misc/code/eval_config/dataset_subset</td><td>all-all</td></tr><tr><td>misc/code/eval_config/dataset_text_key</td><td>code</td></tr><tr><td>misc/code/eval_config/dataset_text_label_key</td><td>label</td></tr><tr><td>misc/code/eval_config/dataset_type</td><td>prediction</td></tr><tr><td>misc/code/eval_config/generated_text_include_prompt</td><td>False</td></tr><tr><td>misc/code/eval_config/generated_text_length</td><td>50</td></tr><tr><td>misc/code/eval_config/generated_text_num_samples</td><td>1</td></tr><tr><td>misc/code/eval_config/is_train_mode</td><td>False</td></tr><tr><td>misc/code/eval_config/loading_bar_desc</td><td>Acc</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen</td><td>0.15</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_masked</td><td>0.8</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_randomized</td><td>0.1</td></tr><tr><td>misc/code/eval_config/masked_frac_chosen_unchanged</td><td>0.1</td></tr><tr><td>misc/code/eval_config/masked_model</td><td>False</td></tr><tr><td>misc/code/eval_config/masked_token_str</td><td><mask></td></tr><tr><td>misc/code/eval_config/n_shot</td><td>0</td></tr><tr><td>misc/code/eval_config/num_texts_to_skip</td><td>0</td></tr><tr><td>misc/code/eval_config/num_tokens_to_skip</td><td>100000.0</td></tr><tr><td>misc/code/eval_config/num_top_tokens</td><td>50</td></tr><tr><td>misc/code/eval_config/sample_size</td><td>100000.0</td></tr><tr><td>misc/code/eval_config/start_index</td><td>0</td></tr><tr><td>misc/code/eval_config/streaming</td><td>True</td></tr><tr><td>misc/code/eval_config/topk</td><td>10</td></tr><tr><td>misc/code/eval_config/verbose</td><td>False</td></tr><tr><td>misc/pile/accuracy_data/num_accurate</td><td>2208</td></tr><tr><td>misc/pile/accuracy_data/num_predictions</td><td>134291</td></tr><tr><td>misc/pile/accuracy_data/num_skip_accurate</td><td>12</td></tr><tr><td>misc/pile/accuracy_data/num_skip_predictions</td><td>100202</td></tr><tr><td>misc/pile/accuracy_data/num_topk_accurate</td><td>5395</td></tr><tr><td>misc/pile/accuracy_data/num_topk_skip_accurate</td><td>461</td></tr><tr><td>misc/pile/eval_config/dataset_has_test_split</td><td>True</td></tr><tr><td>misc/pile/eval_config/dataset_image_key</td><td>image</td></tr><tr><td>misc/pile/eval_config/dataset_image_label_key</td><td>label</td></tr><tr><td>misc/pile/eval_config/dataset_name</td><td>pile</td></tr><tr><td>misc/pile/eval_config/dataset_repo</td><td>monology/pile-uncopy...</td></tr><tr><td>misc/pile/eval_config/dataset_text_key</td><td>text</td></tr><tr><td>misc/pile/eval_config/dataset_text_label_key</td><td>label</td></tr><tr><td>misc/pile/eval_config/dataset_type</td><td>prediction</td></tr><tr><td>misc/pile/eval_config/generated_text_include_prompt</td><td>False</td></tr><tr><td>misc/pile/eval_config/generated_text_length</td><td>50</td></tr><tr><td>misc/pile/eval_config/generated_text_num_samples</td><td>1</td></tr><tr><td>misc/pile/eval_config/is_train_mode</td><td>False</td></tr><tr><td>misc/pile/eval_config/loading_bar_desc</td><td>Acc</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen</td><td>0.15</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_masked</td><td>0.8</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_randomized</td><td>0.1</td></tr><tr><td>misc/pile/eval_config/masked_frac_chosen_unchanged</td><td>0.1</td></tr><tr><td>misc/pile/eval_config/masked_model</td><td>False</td></tr><tr><td>misc/pile/eval_config/masked_token_str</td><td><mask></td></tr><tr><td>misc/pile/eval_config/n_shot</td><td>0</td></tr><tr><td>misc/pile/eval_config/num_texts_to_skip</td><td>0</td></tr><tr><td>misc/pile/eval_config/num_tokens_to_skip</td><td>100000.0</td></tr><tr><td>misc/pile/eval_config/num_top_tokens</td><td>50</td></tr><tr><td>misc/pile/eval_config/sample_size</td><td>100000.0</td></tr><tr><td>misc/pile/eval_config/start_index</td><td>0</td></tr><tr><td>misc/pile/eval_config/streaming</td><td>True</td></tr><tr><td>misc/pile/eval_config/topk</td><td>10</td></tr><tr><td>misc/pile/eval_config/verbose</td><td>False</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test notebook2</strong> at: <a href='https://wandb.ai/seperability/bens-tests/runs/437b6ii6' target=\"_blank\">https://wandb.ai/seperability/bens-tests/runs/437b6ii6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240514_210049-437b6ii6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:437b6ii6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7b306e89c42c395d46e878f3fc796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669637244194745, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/taker/examples/aisc-peak-activations/wandb/run-20240514_212323-d3yincpa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seperability/bens-tests/runs/d3yincpa' target=\"_blank\">test notebook2</a></strong> to <a href='https://wandb.ai/seperability/bens-tests' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seperability/bens-tests' target=\"_blank\">https://wandb.ai/seperability/bens-tests</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seperability/bens-tests/runs/d3yincpa' target=\"_blank\">https://wandb.ai/seperability/bens-tests/runs/d3yincpa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c38af35bc249e8b23eb73e5865060b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 16.45|5.60 (Skip: 10.62|3.94): : 100202it [00:34, 2897.22it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 6.19|2.29 (Skip: 6.69|2.54): : 100190it [00:37, 2685.61it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d924e9e007954b03b9a6a86895f89af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 10.73|2.83 (Skip: 6.92|1.87): : 100202it [00:35, 2819.99it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 2.84|0.52 (Skip: 2.87|0.53): : 100190it [00:36, 2721.10it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b08f454da4cd88df3d8a63ffdba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 8.12|2.43 (Skip: 5.66|1.78): : 100202it [00:34, 2917.71it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 2.42|0.60 (Skip: 2.77|0.62): : 100190it [00:36, 2782.51it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0fcdca12804fd3a84b1b565ca7c027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 6.46|1.70 (Skip: 4.47|1.20): : 100202it [00:34, 2943.53it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 1.55|0.29 (Skip: 1.72|0.29): : 100190it [00:36, 2758.14it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6dd07f09b240319b9483ef906dba94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 3.04|0.51 (Skip: 2.12|0.42): : 100202it [00:33, 2985.43it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.40|0.06 (Skip: 0.40|0.07): : 100190it [00:36, 2757.19it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a57b79fc90f4d5aa26a5404c3afc043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 3.41|0.77 (Skip: 1.95|0.35): : 100202it [00:33, 2957.15it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.69|0.14 (Skip: 0.70|0.15): : 100190it [00:36, 2740.51it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478fe6f7ba0a4f9db99b7da5f6473394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 2.80|0.69 (Skip: 1.27|0.19): : 100202it [00:34, 2925.39it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.31|0.07 (Skip: 0.23|0.04): : 100190it [00:36, 2739.14it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3622af26de1f4e198589d7d3c8a51707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 1.81|0.36 (Skip: 0.67|0.08): : 100202it [00:34, 2862.97it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.43|0.03 (Skip: 0.23|0.02): : 100190it [00:36, 2750.60it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b86ffab26491ab310201c4781318f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.67|0.15 (Skip: 0.23|0.02): : 100202it [00:35, 2838.38it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 0.30|0.06 (Skip: 0.08|0.01): : 100190it [00:36, 2756.50it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "/home/ubuntu/taker/src/taker/model.py:1329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mlp_remove_indices = torch.tensor(mlp_remove_indices).to(self.device)\n",
      "/home/ubuntu/taker/src/taker/model.py:1142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e38623131e4d8cb87408d0699d3ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 4.02|1.64 (Skip: 0.46|0.01): : 100202it [00:35, 2852.83it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]/home/ubuntu/taker/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/github-code-clean contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/github-code-clean\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pile_deduped' has no 'test' split. Using 'train' split and skipping 1000 texts instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 3.26|1.83 (Skip: 0.93|0.01): : 100190it [00:36, 2722.40it/s]                           \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 256112 bytes\n"
     ]
    }
   ],
   "source": [
    "c = PruningConfig(\"nickypro/tinyllama-15m\",\n",
    "    attn_mode=\"pre-out\", do_attn_mean_offset=False, use_accelerator=False,\n",
    "    ff_frac=0.1, attn_frac=0.1,\n",
    "    token_limit=1000, focus=\"pile\", cripple=\"code\", wandb_entity=\"seperability\", recalculate_activations=False,\n",
    "    wandb_project=\"bens-tests\", wandb_run_name=\"test notebook2\", n_steps=10, scoring_normalization=\"peak_centered\")\n",
    "    #wandb_project=\"bens-tests\", wandb_run_name=\"test notebook2\", n_steps=10)\n",
    "\n",
    "opt: Model = Model(c.model_repo, limit=c.token_limit, dtype=\"fp32\",\n",
    "            use_accelerator=c.use_accelerator)\n",
    "focus_data = get_midlayer_activations( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True )\n",
    "cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True )\n",
    "\n",
    "# [token, layer, neuron] -> [layer, neuron, token]\n",
    "focus_ff_activations   = focus_data.raw[\"ff\"].permute( (1,2,0) )\n",
    "cripple_ff_activations = cripple_data.raw[\"ff\"].permute( (1,2,0) )\n",
    "# [token, layer, attention head, attention neuron] -> [layer, attention head, attention neuron, token]\n",
    "focus_attn_activations   = focus_data.raw[\"attn\"].permute( (1,2,3,0) ).reshape( (opt.cfg.n_layers, opt.cfg.d_model, -1) )\n",
    "cripple_attn_activations = cripple_data.raw[\"attn\"].permute( (1,2,3,0) ).reshape( (opt.cfg.n_layers, opt.cfg.d_model, -1) )\n",
    "\n",
    "focus_ff_peaks = get_bucket_peaks(focus_ff_activations).cuda()\n",
    "cripple_ff_peaks = get_bucket_peaks(cripple_ff_activations).cuda()\n",
    "\n",
    "focus_attn_peaks = get_bucket_peaks(focus_attn_activations).reshape(6, 6, 48).cuda()\n",
    "cripple_attn_peaks = get_bucket_peaks(cripple_attn_activations).reshape(6, 6, 48).cuda()\n",
    "\n",
    "# test reversing the shapes of the activatons\n",
    "#print(f\"ff reshaped:  + {focus_ff_activations.shape}\")\n",
    "#print(f\"ff original:  + {focus_data.raw['ff'].shape}\")\n",
    "#print(f\"ff peaks:  + {focus_ff_peaks.shape}\")\n",
    "\n",
    "#same thing with attn\n",
    "#print(f\"attn reshaped:  + {focus_attn_activations.shape}\")\n",
    "#print(f\"attn original:  + {focus_data.raw['attn'].shape}\")\n",
    "#print(f\"attn peaks:  + {focus_attn_peaks.shape}\")\n",
    "\n",
    "# Now get activation data again with peaks offsets\n",
    "focus_data   = get_midlayer_activations( opt, \"pile\", 1e4, collect_ff=True, collect_attn=True, ff_peak=focus_ff_peaks, attn_peak=focus_attn_peaks )\n",
    "cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True, ff_peak=cripple_ff_peaks,  attn_peak=cripple_attn_peaks )\n",
    "\n",
    "#print(\"focus data: \")\n",
    "#print(focus_data.ff.peak_centered)\n",
    "#only ff peaks\n",
    "#cripple_data = get_midlayer_activations( opt, \"code\", 1e4, collect_ff=True, collect_attn=True, ff_peak=cripple_ff_peaks)\n",
    "\n",
    "history = RunDataHistory(c.datasets)\n",
    "wandb.init(\n",
    "    project=c.wandb_project,\n",
    "    entity=c.wandb_entity,\n",
    "    name=c.wandb_run_name,\n",
    "    )\n",
    "wandb.config.update(c.to_dict(), allow_val_change=True)\n",
    "with torch.no_grad():\n",
    "    for i in range(c.n_steps):\n",
    "        data = prune_and_evaluate(opt, c, focus_data, cripple_data, i)\n",
    "        history.add(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
